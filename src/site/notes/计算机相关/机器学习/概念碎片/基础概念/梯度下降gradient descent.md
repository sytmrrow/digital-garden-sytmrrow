---
{"dg-publish":true,"permalink":"/计算机相关/机器学习/概念碎片/基础概念/梯度下降gradient descent/","dgPassFrontmatter":true,"created":"2025-05-09T01:05:25.081+08:00","updated":"2025-05-09T02:17:23.264+08:00"}
---

梯度下降是一种用于寻找函数最小值的优化算法。
在机器学习中，我们用它在最小化[[计算机相关/机器学习/概念碎片/基础概念/损失函数 loss function\|损失函数 loss function]]，目的是让模型预测尽量接近真实值。

“顺着最陡的下坡路走”，一步步接近最优解。

# 梯度gradient
多维函数在当前点的“最快上升方向”

# 梯度下降 
我们要找最小点，顺着梯度的反方向走。
![Pasted image 20250509014859.png](/img/user/Pasted%20image%2020250509014859.png)
步长与[[计算机相关/机器学习/概念碎片/基础概念/学习率learning rate\|学习率learning rate]]有关，如果学习率过大可能会导致跳过最小点或发散，学习率太小收敛太慢。